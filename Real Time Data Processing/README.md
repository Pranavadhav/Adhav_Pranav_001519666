# Real-time Data Processing with Apache Kafka, Spark Streaming, and AWS Services
Engineered a real-time stock market data pipeline leveraging Python, Apache Kafka, and Apache Spark Streaming. Optimized data processing through Spark submit commands, resulting in a remarkable 60% reduction in processing time and enabling the seamless loading of terabytes of transformed data into Amazon S3. Orchestrated workflows with Apache Airflow, ensuring integration and scheduling tasks for Amazon Redshift. Deployed AWS Glue for schema detection, streamlining manual efforts by 25%, and harnessed DBT to refine data warehousing. Further enhanced data visualization using AWS tools, exploring options like Amazon QuickSight for intuitive insights.

![Pipeline Diagram](Real Time Data Processing/aws/Screenshot (387).png)
